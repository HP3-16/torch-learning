{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.w00 = nn.Parameter(torch.tensor(1.7),requires_grad=False)\n",
    "        self.b00 = nn.Parameter(torch.tensor(-0.85),requires_grad=False)\n",
    "        self.w01 = nn.Parameter(torch.tensor(-40.8),requires_grad=False)\n",
    "\n",
    "        self.w10 = nn.Parameter(torch.tensor(12.6),requires_grad=False)\n",
    "        self.b10 = nn.Parameter(torch.tensor(0.0),requires_grad=False)\n",
    "        self.w11 = nn.Parameter(torch.tensor(2.7),requires_grad=False)\n",
    "\n",
    "        self.bfinal = nn.Parameter(torch.tensor(-16),requires_grad=False)\n",
    "    \n",
    "    def forward(self,input):\n",
    "        input_to_relu1 = input*self.w00 + self.b00\n",
    "        relu1_out = F.relu(input_to_relu1)\n",
    "        scaled_relu1_out = relu1_out*self.w01\n",
    "\n",
    "        input_to_relu2 = input*self.w10 + self.b10\n",
    "        relu2_out = F.relu(input_to_relu2)\n",
    "        scaled_relu2_out = relu2_out*self.w11\n",
    "\n",
    "        input_to_final_relu = scaled_relu1_out + scaled_relu2_out + self.bfinal\n",
    "\n",
    "        output = F.relu(input_to_final_relu)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicNN_train(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.w00 = nn.Parameter(torch.tensor(1.7),requires_grad=False)\n",
    "        self.b00 = nn.Parameter(torch.tensor(-0.85),requires_grad=False)\n",
    "        self.w01 = nn.Parameter(torch.tensor(-40.8),requires_grad=False)\n",
    "\n",
    "        self.w10 = nn.Parameter(torch.tensor(12.6),requires_grad=False)\n",
    "        self.b10 = nn.Parameter(torch.tensor(0.0),requires_grad=False)\n",
    "        self.w11 = nn.Parameter(torch.tensor(2.7),requires_grad=False)\n",
    "\n",
    "        self.bfinal = nn.Parameter(torch.tensor(0.0),requires_grad=True)\n",
    "    \n",
    "    def forward(self,input):\n",
    "        input_to_relu1 = input*self.w00 + self.b00\n",
    "        relu1_out = F.relu(input_to_relu1)\n",
    "        scaled_relu1_out = relu1_out*self.w01\n",
    "\n",
    "        input_to_relu2 = input*self.w10 + self.b10\n",
    "        relu2_out = F.relu(input_to_relu2)\n",
    "        scaled_relu2_out = relu2_out*self.w11\n",
    "\n",
    "        input_to_final_relu = scaled_relu1_out + scaled_relu2_out + self.bfinal\n",
    "\n",
    "        output = F.relu(input_to_final_relu)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = torch.linspace(0,1,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BasicNN_train()\n",
    "output_val = model(input_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  3.4020,  6.8040, 10.2060, 13.6080, 17.0100, 13.4760,  9.9420,\n",
       "         6.4080,  2.8740,  0.0000], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "inputs = torch.tensor([0.,0.5,0.])\n",
    "labels = torch.tensor([0.,1.,0.])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tensor(0.)'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(model.bfinal.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final bias before optm is tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "optmizer = SGD(model.parameters(),lr=0.1)\n",
    "\n",
    "print(\"Final bias before optm is {}\".format(str(model.bfinal.data)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bfinal change >> tensor(-3.2020)\n",
      "bfinal change >> tensor(-5.7636)\n",
      "bfinal change >> tensor(-7.8129)\n",
      "bfinal change >> tensor(-9.4523)\n",
      "bfinal change >> tensor(-10.7638)\n",
      "bfinal change >> tensor(-11.8131)\n",
      "bfinal change >> tensor(-12.6525)\n",
      "bfinal change >> tensor(-13.3240)\n",
      "bfinal change >> tensor(-13.8612)\n",
      "bfinal change >> tensor(-14.2909)\n",
      "bfinal change >> tensor(-14.6348)\n",
      "bfinal change >> tensor(-14.9098)\n",
      "bfinal change >> tensor(-15.1298)\n",
      "bfinal change >> tensor(-15.3059)\n",
      "bfinal change >> tensor(-15.4467)\n",
      "bfinal change >> tensor(-15.5594)\n",
      "bfinal change >> tensor(-15.6495)\n",
      "bfinal change >> tensor(-15.7216)\n",
      "bfinal change >> tensor(-15.7793)\n",
      "bfinal change >> tensor(-15.8254)\n",
      "bfinal change >> tensor(-15.8623)\n",
      "bfinal change >> tensor(-15.8919)\n",
      "bfinal change >> tensor(-15.9155)\n",
      "bfinal change >> tensor(-15.9344)\n",
      "bfinal change >> tensor(-15.9495)\n",
      "bfinal change >> tensor(-15.9616)\n",
      "bfinal change >> tensor(-15.9713)\n",
      "bfinal change >> tensor(-15.9790)\n",
      "bfinal change >> tensor(-15.9852)\n",
      "bfinal change >> tensor(-15.9902)\n",
      "bfinal change >> tensor(-15.9941)\n",
      "bfinal change >> tensor(-15.9973)\n",
      "bfinal change >> tensor(-15.9999)\n",
      "bfinal change >> tensor(-16.0019)\n",
      "Num epochs = 34\n",
      "Final_bias is tensor(-16.0019)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "\n",
    "    total_loss = 0 # How model fits the data\n",
    "\n",
    "    for i in range(len(inputs)):\n",
    "        input_i = inputs[i]\n",
    "        label_i = labels[i]\n",
    "\n",
    "        label_pred = model(input_i)\n",
    "\n",
    "        loss_i = (label_pred - label_i)**2\n",
    "        loss_i.backward()\n",
    "\n",
    "        total_loss+=float(loss_i)\n",
    "    \n",
    "    if(total_loss<0.0001):\n",
    "        print(\"Num epochs = {}\".format(str(epoch)))\n",
    "        break\n",
    "    optmizer.step()\n",
    "    optmizer.zero_grad()\n",
    "\n",
    "    print(\"bfinal change >> {}\".format(str(model.bfinal.data)))\n",
    "\n",
    "print(\"Final_bias is {}\".format(str(model.bfinal.data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
